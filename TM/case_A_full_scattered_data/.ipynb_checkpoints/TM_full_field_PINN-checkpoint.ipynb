{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03303803-dab5-4cf5-af6d-f5d6d117d059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd4cafc-6a0b-4bcd-ac8b-15520f05f696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wavenumber and wavelength\n",
    "k = 2.0 * np.pi\n",
    "lamb =  2.0 * np.pi / k\n",
    "\n",
    "# domain [la,lb]\n",
    "la = -8.0 * lamb\n",
    "lb = 8.0 * lamb\n",
    "\n",
    "# define the mesh for observation\n",
    "N_obs = 240\n",
    "h_obs = (lb - la) / N_obs\n",
    "mesh_obs = np.linspace(la, lb, (N_obs + 1))\n",
    "\n",
    "mesh_mid_obs = np.zeros(N_obs + 1)\n",
    "\n",
    "mesh_mid_obs[0] = la\n",
    "\n",
    "for od in range(N_obs):\n",
    "    mesh_mid_obs[od + 1] = (mesh_obs[od] + mesh_obs[od+1])/2.0\n",
    "\n",
    "# transform numpy mesh to torch mesh\n",
    "x_mid_obs = torch.tensor(mesh_mid_obs, dtype = torch.float32, requires_grad = True)\n",
    "x_mesh_obs = torch.tensor(mesh_obs, dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "# define the maximum number of testing points\n",
    "N_inv = 480\n",
    "\n",
    "# define the max and min of surface height\n",
    "hmax = 0.2 * lamb\n",
    "hmin = -0.2 * lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3afcc176-2900-4fd6-ba78-2b92a1da63a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# angle of grazing\n",
    "alpha = torch.tensor([[-1.0 * np.pi / 4.0]])\n",
    "\n",
    "# the incident wave, which is a plane wave\n",
    "def inc_field(x, z):\n",
    "    g = torch.cos(alpha) * x + torch.sin(alpha) * z\n",
    "    return torch.exp(1.0 * 1j * k * g)\n",
    "\n",
    "# observation height \n",
    "zp = lamb * 0.4\n",
    "\n",
    "# Hankel function of first order of first kind\n",
    "def hankel(sth):\n",
    "    return torch.special.bessel_j1(sth) + 1j * torch.special.bessel_y1(sth)\n",
    "\n",
    "# method of moments\n",
    "def MOM(x_mid, hei_vec, heid_vec, heidd_vec):\n",
    "    ''' This function implements the method of moments.\n",
    "     x_mid is the mesh points.\n",
    "     hei_vec is the torch tensor for the surface height.\n",
    "     heid_vec is the torch tensor of the derivative of surface height.\n",
    "     heidd_vec is the torch tensor of the second order derivative of surface height.\n",
    "     it reaturns the torch tensor of scattered field.'''\n",
    "    \n",
    "    h = x_mid[100] - x_mid[99]\n",
    "    N = x_mid.numel() - 1\n",
    "    \n",
    "    # aseemble surface incident field\n",
    "    inc_vec =  torch.zeros(N, dtype=torch.cfloat)\n",
    "    for i in range(N):\n",
    "        inc_vec[i] = inc_field(x_mid[i+1], hei_vec[i+1])\n",
    "        \n",
    "    # aseemble matrix A\n",
    "    A =  torch.zeros((N, N), dtype=torch.cfloat)\n",
    "    \n",
    "    # off-diagonal terms\n",
    "    def getA_offdiag1(nn):\n",
    "        ll = torch.arange(1, nn)\n",
    "        ptl = torch.sqrt((x_mid[nn] - x_mid[ll]) ** 2 + (hei_vec[nn] - hei_vec[ll])**2)\n",
    "        inte1 = hankel(k * ptl) / ptl\n",
    "        inte2 = -1.0 * heid_vec[ll] * (x_mid[nn] - x_mid[ll]) + (hei_vec[nn] - hei_vec[ll])\n",
    "        sd = torch.sqrt(1.0 + heid_vec[ll] ** 2)\n",
    "        return 1.0 * k * 1j / 4.0 * h * inte1 * inte2 * sd \n",
    "    def getA_offdiag2(nn):\n",
    "        ll = torch.arange(nn + 1, N + 1)\n",
    "        ptl = torch.sqrt((x_mid[nn] - x_mid[ll]) ** 2 + (hei_vec[nn] - hei_vec[ll])**2)\n",
    "        inte1 = hankel(k * ptl) / ptl\n",
    "        inte2 = -1.0 * heid_vec[ll] * (x_mid[nn] - x_mid[ll]) + (hei_vec[nn] - hei_vec[ll])\n",
    "        sd = torch.sqrt(1.0 + heid_vec[ll] ** 2)\n",
    "        return 1.0 * k * 1j / 4.0 * h * inte1 * inte2 * sd \n",
    "    \n",
    "    # diagonal terms\n",
    "    def getA_diag(nn):\n",
    "        return 1.0 * h * k * heidd_vec[nn] / ((1.0 + heid_vec[nn] ** 2) * 4 * torch.pi)\n",
    "\n",
    "    for nu in range(N):\n",
    "        A[nu, 0:nu] = -1.0 * getA_offdiag1(nu + 1)\n",
    "        A[nu, nu+1:N] = -1.0 * getA_offdiag2(nu + 1)\n",
    "        A[nu, nu] = -1.0 * getA_diag(nu + 1) + torch.tensor([0.5])\n",
    "    \n",
    "    # solve for surface current\n",
    "    phid = torch.linalg.solve(A, inc_vec)\n",
    "    \n",
    "    zz = torch.tensor([zp])\n",
    "    \n",
    "    # assemble matrix B\n",
    "    B =  torch.zeros((N, N), dtype=torch.cfloat)\n",
    "\n",
    "    # components of matrix B\n",
    "    def getB(nn):\n",
    "        rr = torch.arange(1, N + 1)\n",
    "        ptl = torch.sqrt((x_mid[nn] - x_mid[rr]) ** 2 + (zz - hei_vec[rr])**2)\n",
    "        inte1 = hankel(k * ptl) / ptl\n",
    "        inte2 = -1.0 * heid_vec[rr] * (x_mid[nn] - x_mid[rr]) + (zz - hei_vec[rr])\n",
    "        sd = torch.sqrt(1.0 + heid_vec[rr] ** 2)\n",
    "        return 1.0 * k * h * 1j / 4.0 * inte1 * inte2 * sd \n",
    "    \n",
    "    for nd in range(N):\n",
    "        B[nd, 0:N] = getB(nd + 1)\n",
    "\n",
    "    # calculate scattered field\n",
    "    phis = torch.matmul(B, phid)\n",
    "    \n",
    "    return phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c71a04-47f7-4347-8dac-c15a1341a343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the data of actual surface \n",
    "hei_actual_torch = torch.load('./vector_true_surface.pt')\n",
    "\n",
    "# load the data list of the interpolated scattered field\n",
    "# data without noise\n",
    "data_phis_without_noise = torch.load('./data_scattered_field_without_noise.pt')\n",
    "# data with noise\n",
    "data_phis_with_noise = torch.load('data_scattered_field_with_noise.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea5e3a8-193e-4daa-8e25-06ee81aea493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# main structure for the neural network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    # NL: the number of hidden layers\n",
    "    # NN: the number of vertices in each layer\n",
    "    def __init__(self, NL, NN):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(1, NN)\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(NN, NN) for i in range(NL)])\n",
    "\n",
    "        self.output_layer = nn.Linear(NN, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.act(self.input_layer(x))\n",
    "\n",
    "        for i, li in enumerate(self.hidden_layers):\n",
    "            o = self.act(li(o))\n",
    "        \n",
    "        out = self.output_layer(o)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def act(self, x):\n",
    "        return x * torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec647962-ee32-4522-b143-6c27e694c5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define MSE loss for complex-valued tensors\n",
    "\n",
    "def complex_mse_loss(input_tensor, target_tensor):\n",
    "    \n",
    "    # Split input and target tensors into real and imaginary parts\n",
    "    input_real, input_imag = input_tensor.real, input_tensor.imag\n",
    "    target_real, target_imag = target_tensor.real, target_tensor.imag\n",
    "\n",
    "    # Calculate squared error for real and imaginary components separately\n",
    "    real_mse_loss = torch.mean((input_real - target_real) ** 2)\n",
    "    imag_mse_loss = torch.mean((input_imag - target_imag) ** 2)\n",
    "\n",
    "    # Combine the real and imaginary losses\n",
    "    mse_loss = real_mse_loss + imag_mse_loss\n",
    "\n",
    "    return mse_loss\n",
    "\n",
    "# at each epoch, we generate a mesh of size N_t, N_t is inside [N_obs, N_inv]\n",
    "def generate_mesh():\n",
    "    \n",
    "    # first generate a random number N_t\n",
    "    N_t = torch.randint(N_obs, N_inv + 1, (1,)).item()\n",
    "    \n",
    "    # identify the position in the data list\n",
    "    idx = N_t - N_obs\n",
    "    \n",
    "    # generate the mesh\n",
    "    x_mesh = torch.linspace(la,lb, N_t+1, requires_grad = True).view(-1,1)\n",
    "    x_train = torch.zeros(N_t + 1)\n",
    "    x_train[0] = la\n",
    "    for od in range(N_t):\n",
    "        x_train[od + 1] = (x_mesh[od] + x_mesh[od+1])/2.0\n",
    "        \n",
    "    return idx, x_train, N_t\n",
    "    \n",
    "# normalization of a tensor\n",
    "def normalize_tensor(input_tensor):\n",
    "    \n",
    "    min_val = input_tensor.min()\n",
    "    max_val = input_tensor.max()\n",
    "    normalized_tensor = 2 * (input_tensor - min_val) / (max_val - min_val) - 1\n",
    "    \n",
    "    return normalized_tensor\n",
    "\n",
    "# the inverse normalization of a tensor\n",
    "def inverse_normalize_tensor(normalized_tensor, original_max, original_min):\n",
    "    \n",
    "    # Compute the scale and shift parameters\n",
    "    scale = (original_max - original_min) / 2\n",
    "    shift = (original_max + original_min) / 2\n",
    "    \n",
    "    inverse_normalized_tensor = normalized_tensor * scale + shift\n",
    "    return inverse_normalized_tensor\n",
    "\n",
    "# the automatic differentiation gives the first order derivative of normalization of output\n",
    "# w.r.t. normalizaton of input, applying the chain rule function leads to the\n",
    "# actual first order derivative of target output w.r.t. target input\n",
    "def chain_rule_first_order(first_order_derivative_tensor, output_max, output_min, input_max, input_min):\n",
    "    return (output_max - output_min) * first_order_derivative_tensor / (input_max - input_min)\n",
    "\n",
    "# the automatic differentiation gives the second order derivative of normalization of output\n",
    "# w.r.t. normalizaton of input, applying this chain rule function leads to the\n",
    "# actual second order derivative of target output w.r.t. target input\n",
    "def chain_rule_second_order(second_order_derivative_tensor, output_max, output_min, input_max, input_min):\n",
    "    return 2.0 * (output_max - output_min) * second_order_derivative_tensor / ((input_max - input_min) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dbdc4e-c9ca-4972-91b8-5d908fce56a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up parameters for PINN neural networks\n",
    "# NL is number of hidden layers and NN is the number of neurons per hidden layer\n",
    "net = Net(NL=4, NN=256)\n",
    "# choose an optimizer and learning rate\n",
    "optimizer = optim.Adam(net.parameters(), lr = 1E-3)\n",
    "# set number of iterations\n",
    "N_PINN = 3000\n",
    "\n",
    "# this is the main loop for the PINN\n",
    "for t in range(N_PINN):\n",
    "    \n",
    "    # first step, generate N_t and the mesh\n",
    "    idx, x_train_ori, N_t = generate_mesh()\n",
    "    \n",
    "    # normalization of points\n",
    "    x_train = normalize_tensor(x_train_ori)\n",
    "    \n",
    "    # forward propagation\n",
    "    x_train = x_train.view(-1,1)\n",
    "    y = net(x_train)\n",
    "    \n",
    "    # use automatic differentiation to find derivatives\n",
    "    dy = torch.autograd.grad(y, x_train, grad_outputs= torch.ones(y.size()), create_graph = True)[0] \n",
    "    ddy = torch.autograd.grad(dy, x_train, grad_outputs= torch.ones(y.size()), create_graph = True)[0] \n",
    "    \n",
    "    # transform the surface to 1D vector and apply inverse normalization\n",
    "    hei_pred_net = y.view(-1)\n",
    "    hei_pred = inverse_normalize_tensor(hei_pred_net, hmax, hmin)\n",
    "    \n",
    "    # transform first order derivative to 1D vector and apply the chain rule\n",
    "    heid_pred_net = dy.view(-1)\n",
    "    heid_pred = chain_rule_first_order(heid_pred_net, hmax, hmin, x_train_ori.max(), x_train_ori.min())\n",
    "    \n",
    "    # transform second order derivative to 1D vector and apply the chain rule\n",
    "    heidd_pred_net = ddy.view(-1)\n",
    "    heidd_pred = chain_rule_second_order(heidd_pred_net, hmax, hmin, x_train_ori.max(), x_train_ori.min())\n",
    "\n",
    "    # use MOM to calculate the scattered field\n",
    "    phis_pred = MOM(x_train_ori, hei_pred, heid_pred, heidd_pred)\n",
    "    \n",
    "    # identify the corresponding observed scattered data\n",
    "    phis_obs = data_phis_with_noise[idx]\n",
    "    \n",
    "    # MSE loss of the residual of equation\n",
    "    loss_eqn = complex_mse_loss(phis_pred, phis_obs)\n",
    "    \n",
    "    # find the predicted surface values on the close-boundary points\n",
    "    indices_bc = torch.tensor([0, 1, 2, 3, 4, N_t, N_t - 1, N_t - 2, N_t - 3, N_t - 4])\n",
    "    pred_bc = hei_pred[indices_bc]\n",
    "    \n",
    "    # MSE loss of boundary values\n",
    "    loss_bc = torch.nn.MSELoss()(pred_bc, torch.zeros(10))\n",
    "    \n",
    "    # the total loss is the combination \n",
    "    loss = loss_eqn + loss_bc \n",
    "    \n",
    "    # optimizing step with backward propagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "#     print(f\"Epoch {t}, Loss: {loss.item()}\")\n",
    "    if (t + 1) % 100 == 0:\n",
    "        print(f\"Epoch {t}, Loss: {loss.item()}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d44fa2d-ea22-4519-81b0-3fb8b6e33c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalization of testing points\n",
    "x_mesh_test = normalize_tensor(x_mesh_obs)\n",
    "\n",
    "# forward propagation and inverse normalization to obtain the result surface height\n",
    "y = net(x_mesh_test.view(-1,1)).view(-1)\n",
    "hei_pred_output = inverse_normalize_tensor(y, hmax, hmin)\n",
    "\n",
    "# transform torch tensors to numpy arrays\n",
    "hei_actual_vec = hei_actual_torch.detach().numpy()\n",
    "hei_pred_vec = hei_pred_output.detach().numpy()\n",
    "\n",
    "# plot the result\n",
    "plt.figure(figsize=[8, 6])\n",
    "line1, = plt.plot(mesh_mid_obs / lamb, hei_actual_vec / lamb, color='r', linewidth = 2)\n",
    "line2, = plt.plot(mesh_mid_obs / lamb, hei_pred_vec / lamb, color='b', linewidth=2, linestyle = '--', fillstyle = 'none')\n",
    "plt.xlabel(r'$x/{\\lambda}$', fontsize = 15)\n",
    "plt.ylabel(r'$z/{\\lambda}$', fontsize = 15)\n",
    "leg=plt.legend([line1, line2],\n",
    "        ['actual surface',\n",
    "        'reconstructed surface'],\n",
    "        prop={'size': 15}, loc = \"best\")\n",
    "plt.gca().tick_params(labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74086491-3c2b-4cc9-b9d2-0f38e58ebde1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the l2 norm error\n",
    "error_vec = hei_actual_vec - hei_pred_vec\n",
    "print(\"l2 norm error is: \", np.linalg.norm(error_vec) / np.linalg.norm(hei_actual_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0827947e-adf1-41d4-b315-c23857d65570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
